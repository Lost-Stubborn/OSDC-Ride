<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Speech to text with Camera</title>
    <style>
        *,
        *:after,
        *:before {
            -webkit-box-sizing: border-box;
            -moz-box-sizing: border-box;
            box-sizing: border-box;
        }

        body {
            font-family: Arial, sans-serif;
            font-size: 16px;
            margin: 0;
            background: linear-gradient(to right bottom, #d13cff, #031f6a);
            display: flex;
            align-items: center;
            justify-content: center;
            min-height: 100vh;
            color: #000;
        }

        .container {
            width: 800px;
            text-align: center;
        }

        #video {
            width: 100%;
            display: none;
            margin-bottom: 20px;
        }

        #convert_text {
            width: 100%;
            height: 200px;
            border-radius: 10px;
            resize: none;
            padding: 10px;
            font-size: 20px;
            margin-bottom: 10px;
        }

        h1 {
            font-size: 50px;
            color: #fff;
            margin-bottom: 20px;
        }

        button {
            padding: 12px 20px;
            background: #0ea4da;
            border: 0;
            border-radius: 5px;
            cursor: pointer;
            color: #fff;
        }

        .hidden{
            visibility: hidden;
        }

        /* .container{
            background:url("../static/music.mp3");
        } */
    </style>
</head>

<body>

    
    <div class="container">
        <h1>Video Interface with Zenayra</h1>
        <video id="video" autoplay></video>
        <textarea id="convert_text" placeholder="Converted speech will appear here"></textarea>
        <button id="voiceToTextBtn">Voice to Text</button>

    </div>

    <script>
		let myAudio = new Audio();
		myAudio.src = '../static/music.mp3';
		myAudio.addEventListener('ended', () => {
			myAudio.play();
		})
		function Gameloop() {
			myAudio.play();
			if (myAudio.paused == true) {
				myAudio.play();
			}
		}
		window.onload = setInterval(Gameloop, 1000 / 10); //10fps
	</script>

    
    <script>
        document.getElementById('voiceToTextBtn').addEventListener('click', function () {
            startCamera();
            startSpeechToText();

        });

        async function startCamera() {
            const video = document.getElementById('video');
            try {
                const stream = await navigator.mediaDevices.getUserMedia({ video: true });
                video.srcObject = stream;
                video.style.display = 'block';
            } catch (error) {
                console.error('Error accessing camera:', error);
            }
        }

        function startSpeechToText() {
            var speech = true;
            window.SpeechRecognition = window.webkitSpeechRecognition || window.SpeechRecognition;
            const recognition = new SpeechRecognition();
            recognition.interimResults = true;

            recognition.addEventListener('result', e => {
                const transcript = Array.from(e.results)
                    .map(result => result[0])
                    .map(result => result.transcript)
                    .join(' '); // Combine all speech pieces into a single string

                document.getElementById('convert_text').value = transcript;

                // Send transcript data to the Flask server via POST request
                fetch('/submit', {
                    method: 'POST',
                    headers: {
                        'Content-Type': 'application/json',
                    },
                    body: JSON.stringify({ transcript: transcript })
                }).then(response => response.json())
                    .then(data => console.log(data))
                    .catch(error => console.error('Error:', error));
            });

            if (speech) {
                recognition.start();
            }
        }
    </script>

    
<script>

    let lastMessage = ''; // Variable to store the last spoken message
    
    // Function to speak the message
    function speakMessage(message) {
        const speech = new SpeechSynthesisUtterance(message);
        window.speechSynthesis.speak(speech);
    }
    
    // Function to fetch and process data
    function fetchDataAndSpeak() {
        // Send a request to retrieve the JSON data from the server
        fetch('/static/data.json')
            .then(response => response.json())
            .then(jsonData => {
                // Process the received JSON data
                console.log('Received data from Python:', jsonData);
    
                // Extract the message from the JSON data
                const message = jsonData.message;
    
                // Check if the new message is different from the last spoken message
                if (message !== lastMessage) {
                    // Speak the message using the Web Speech API
                    speakMessage(message);
    
                    // Update the last spoken message
                    lastMessage = message;
                }
            })
            .catch(error => {
                console.error('Error fetching JSON data:', error);
            });
    } 
    
    // Set an interval to periodically fetch and process data
    const intervalId = setInterval(fetchDataAndSpeak, 5000); // Adjust the interval as needed (in milliseconds)
    
    // Stop the interval after a certain period (e.g., 5 minutes)
    setTimeout(() => {
        clearInterval(intervalId);
    }, 300000); // 300000 milliseconds = 5 minutes
    
    
    </script>

    
</body>

</html>